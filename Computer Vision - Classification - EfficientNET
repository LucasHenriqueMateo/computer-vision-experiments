{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lucashmateo/computer-vision-classification-efficientnet?scriptVersionId=192688486\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Baixar o conjunto de dados do Kaggle\n!kaggle datasets download -d maeloisamignoni/soybeanleafdataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-14T15:05:39.061227Z","iopub.execute_input":"2024-08-14T15:05:39.062151Z","iopub.status.idle":"2024-08-14T15:05:48.672268Z","shell.execute_reply.started":"2024-08-14T15:05:39.062116Z","shell.execute_reply":"2024-08-14T15:05:48.671146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\n\n# Defina o caminho do arquivo zip\nzip_path = '/kaggle/working/soybeanleafdataset.zip'\nextract_path = '/kaggle/working/soybeanleafdataset'\n\n# Crie o diretório de extração, se não existir\nos.makedirs(extract_path, exist_ok=True)\n\n# Extraia o conteúdo do arquivo zip\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall(extract_path)\n\nprint(\"Arquivos extraídos para:\", extract_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:05:48.674756Z","iopub.execute_input":"2024-08-14T15:05:48.675688Z","iopub.status.idle":"2024-08-14T15:05:53.64804Z","shell.execute_reply.started":"2024-08-14T15:05:48.675647Z","shell.execute_reply":"2024-08-14T15:05:53.647008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#diretório de base e classes\nbase_dir = '/kaggle/working/soybeanleafdataset/soybean.leaf.dataset'\nclasses = ['Caterpillar', 'Diabrotica speciosa', 'Healthy']","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:05:53.649359Z","iopub.execute_input":"2024-08-14T15:05:53.649968Z","iopub.status.idle":"2024-08-14T15:05:53.654794Z","shell.execute_reply.started":"2024-08-14T15:05:53.649932Z","shell.execute_reply":"2024-08-14T15:05:53.65376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q torch torchvision timm tensorflow split-folders seaborn split-folders","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:05:53.657423Z","iopub.execute_input":"2024-08-14T15:05:53.657771Z","iopub.status.idle":"2024-08-14T15:06:15.535105Z","shell.execute_reply.started":"2024-08-14T15:05:53.657718Z","shell.execute_reply":"2024-08-14T15:06:15.534115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importar bibliotecas necessárias\n\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch\nimport tensorflow as tf\nimport splitfolders\nimport shutil\nimport seaborn as sns\nimport random\nimport pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision.models import vgg19\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, load_img, img_to_array\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport timm\nimport timm\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\nfrom timm.data.mixup import Mixup\nfrom timm.data.random_erasing import RandomErasing\nfrom torch.optim import lr_scheduler\n\n# Configurar alguns parâmetros de visualização\nsns.set(style=\"whitegrid\")\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['image.cmap'] = 'viridis'","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:06:15.536646Z","iopub.execute_input":"2024-08-14T15:06:15.536939Z","iopub.status.idle":"2024-08-14T15:06:33.748916Z","shell.execute_reply.started":"2024-08-14T15:06:15.536912Z","shell.execute_reply":"2024-08-14T15:06:33.747963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Função para plotar imagens de cada classe\ndef plot_images(class_name, n_images=5):\n    class_dir = os.path.join(base_dir, class_name)\n    if os.path.exists(class_dir):\n        images = os.listdir(class_dir)[:n_images]\n\n        plt.figure(figsize=(15, 5))\n        for i, img_name in enumerate(images):\n            img_path = os.path.join(class_dir, img_name)\n            img = load_img(img_path, target_size=(150, 150))\n            plt.subplot(1, n_images, i+1)\n            plt.imshow(img)\n            plt.title(class_name)\n            plt.axis('off')\n        plt.show()\n    else:\n        print(f'Diretório {class_dir} não encontrado.')\n\n# Visualizar algumas imagens de cada classe\nfor cls in classes:\n    plot_images(cls)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:06:33.750066Z","iopub.execute_input":"2024-08-14T15:06:33.750362Z","iopub.status.idle":"2024-08-14T15:06:36.520376Z","shell.execute_reply.started":"2024-08-14T15:06:33.750337Z","shell.execute_reply":"2024-08-14T15:06:36.519501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verificar a estrutura das pastas e contar o número de imagens em cada classe\nfor cls in classes:\n    class_dir = os.path.join(base_dir, cls)\n    if os.path.exists(class_dir):\n        num_images = len(os.listdir(class_dir))\n        print(f'Classe {cls} contém {num_images} imagens.')\n    else:\n        print(f'Diretório {class_dir} não encontrado.')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:06:36.521564Z","iopub.execute_input":"2024-08-14T15:06:36.521854Z","iopub.status.idle":"2024-08-14T15:06:36.531684Z","shell.execute_reply.started":"2024-08-14T15:06:36.521829Z","shell.execute_reply":"2024-08-14T15:06:36.530804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configurar data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:06:36.533073Z","iopub.execute_input":"2024-08-14T15:06:36.533389Z","iopub.status.idle":"2024-08-14T15:06:36.542705Z","shell.execute_reply.started":"2024-08-14T15:06:36.533365Z","shell.execute_reply":"2024-08-14T15:06:36.541944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport matplotlib.pyplot as plt\n\n# Inicializar o gerador de dados com aumento\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Função para aumentar imagens\ndef augment_images(class_name, target_count):\n    class_dir = os.path.join(base_dir, class_name)\n    images = os.listdir(class_dir)\n    current_count = len(images)\n\n    # Loop até atingir o número desejado de imagens\n    while current_count < target_count:\n        img_name = random.choice(images)\n        img_path = os.path.join(class_dir, img_name)\n        img = load_img(img_path)\n        x = img_to_array(img)  # Converte a imagem em array\n        x = x.reshape((1,) + x.shape)  # Redimensiona para (1, largura, altura, 3)\n\n        # Gerar imagens aumentadas\n        i = 0\n        for batch in datagen.flow(x, batch_size=1, save_to_dir=class_dir, save_prefix='aug', save_format='jpeg'):\n            i += 1\n            if i >= 1:  # Gerar uma imagem aumentada por iteração\n                break\n\n        current_count += 1\n        if current_count % 100 == 0:\n            print(f'{current_count} imagens geradas para a classe {class_name}')\n\n# Número alvo de imagens para cada classe\ntarget_count = 3309\n\n# Aplicar data augmentation nas classes menos representadas\naugment_images('Diabrotica speciosa', target_count)\naugment_images('Healthy', target_count)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:06:36.543878Z","iopub.execute_input":"2024-08-14T15:06:36.544144Z","iopub.status.idle":"2024-08-14T15:09:35.814473Z","shell.execute_reply.started":"2024-08-14T15:06:36.544122Z","shell.execute_reply":"2024-08-14T15:09:35.813678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verificar a estrutura das pastas e contar o número de imagens em cada classe\nfor cls in classes:\n    class_dir = os.path.join(base_dir, cls)\n    if os.path.exists(class_dir):\n        num_images = len(os.listdir(class_dir))\n        print(f'Classe {cls} contém {num_images} imagens.')\n    else:\n        print(f'Diretório {class_dir} não encontrado.')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:09:35.817277Z","iopub.execute_input":"2024-08-14T15:09:35.817542Z","iopub.status.idle":"2024-08-14T15:09:35.829788Z","shell.execute_reply.started":"2024-08-14T15:09:35.81752Z","shell.execute_reply":"2024-08-14T15:09:35.828934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dividir os dados em treino, validação e teste\nsplitfolders.ratio(base_dir,\n                   output=\"dataset\",\n                   seed=100,\n                   ratio=(.7, .2, .1),\n                   group_prefix=None,\n                   move=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:09:35.830952Z","iopub.execute_input":"2024-08-14T15:09:35.831409Z","iopub.status.idle":"2024-08-14T15:09:38.016961Z","shell.execute_reply.started":"2024-08-14T15:09:35.831376Z","shell.execute_reply":"2024-08-14T15:09:38.016121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelo 3.1","metadata":{}},{"cell_type":"code","source":"# Definir diretórios base\ntrain_dir = '/kaggle/working/dataset/train'\nval_dir = '/kaggle/working/dataset/val'\ntest_dir = '/kaggle/working/dataset/test'\n\n# Transformações de dados\ntransformacoes_treino = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    RandomErasing(probability=0.5, mode='const')  # Corrigir o modo para 'const'\n])\ntransformacoes_valid = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntransformacoes_teste = transformacoes_valid\n\n# Carregar dados\ntreino_dataset = datasets.ImageFolder(root=train_dir, transform=transformacoes_treino)\nvalid_dataset = datasets.ImageFolder(root=val_dir, transform=transformacoes_valid)\nteste_dataset = datasets.ImageFolder(root=test_dir, transform=transformacoes_teste)\n\n# Criar DataLoaders\nbatch_size = 32\ntreino_loader = DataLoader(treino_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\nteste_loader = DataLoader(teste_dataset, batch_size=batch_size, shuffle=False)\n\n# Verificar se os dados foram carregados corretamente\nfor images, labels in treino_loader:\n    print(f\"Lote de treino - Imagens: {images.size()}, Labels: {labels.size()}\")\n    break\n\n# Dispositivo de treinamento (GPU se disponível)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:09:38.017996Z","iopub.execute_input":"2024-08-14T15:09:38.018293Z","iopub.status.idle":"2024-08-14T15:09:38.79204Z","shell.execute_reply.started":"2024-08-14T15:09:38.018246Z","shell.execute_reply":"2024-08-14T15:09:38.791023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Carregar o modelo EfficientNet pré-treinado no ImageNet\nmodelo = timm.create_model('efficientnet_b0', pretrained=True)\nnum_ftrs = modelo.classifier.in_features\nmodelo.classifier = nn.Linear(num_ftrs, 3)  # Ajustar para o número de classes (3)\nmodelo = modelo.to(device)\n\n# Definir o otimizador e a função de perda\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(modelo.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n\n# Definir o scheduler ReduceLROnPlateau\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                       mode='min', \n                                                       factor=0.5, \n                                                       patience=5, \n                                                       verbose=True, \n                                                       min_lr=1e-6)\n\n# Função para treinar o modelo\ndef train_model(model, criterion, optimizer, train_loader, valid_loader, scheduler, num_epochs=50):\n    train_loss_history = []\n    val_loss_history = []\n    train_accuracy_history = []\n    val_accuracy_history = []\n\n    print(\"\\nTreinamento Iniciado!\\n\")\n\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset) * 100\n\n        train_loss_history.append(epoch_loss)\n        train_accuracy_history.append(epoch_acc.item())\n\n        model.eval()\n        val_running_loss = 0.0\n        val_running_corrects = 0\n\n        with torch.no_grad():\n            for inputs, labels in valid_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                _, preds = torch.max(outputs, 1)\n                val_running_loss += loss.item() * inputs.size(0)\n                val_running_corrects += torch.sum(preds == labels.data)\n\n        val_loss = val_running_loss / len(valid_loader.dataset)\n        val_acc = val_running_corrects.double() / len(valid_loader.dataset) * 100\n\n        val_loss_history.append(val_loss)\n        val_accuracy_history.append(val_acc.item())\n\n        # Atualizar o scheduler\n        scheduler.step(val_loss)\n\n        print(f'Epoch: {epoch} - Acurácia em Treino: {epoch_acc:.2f} - Acurácia em Validação: {val_acc:.2f} - Erro em Treino: {epoch_loss:.4f} - Erro em Validação: {val_loss:.4f}')\n\n    print(\"\\nTreinamento Concluído!\\n\")\n    return train_accuracy_history, val_accuracy_history, train_loss_history, val_loss_history\n\n# Treinar o modelo\ntrain_accuracy_history, val_accuracy_history, train_loss_history, val_loss_history = train_model(modelo, criterion, optimizer, treino_loader, valid_loader, scheduler, num_epochs=100)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:09:38.793326Z","iopub.execute_input":"2024-08-14T15:09:38.793616Z","iopub.status.idle":"2024-08-14T18:25:16.501767Z","shell.execute_reply.started":"2024-08-14T15:09:38.793592Z","shell.execute_reply":"2024-08-14T18:25:16.500758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_model(model, test_loader):\n    model.eval()\n    test_running_loss = 0.0\n    test_running_corrects = 0\n\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            _, preds = torch.max(outputs, 1)\n            test_running_loss += loss.item() * inputs.size(0)\n            test_running_corrects += torch.sum(preds == labels.data)\n\n    test_loss = test_running_loss / len(test_loader.dataset)\n    test_acc = test_running_corrects.double() / len(test_loader.dataset) * 100\n\n    print(f'Acurácia em Teste: {test_acc:.2f} - Erro em Teste: {test_loss:.4f}')\n    return test_acc.item(), test_loss\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T18:25:16.50333Z","iopub.execute_input":"2024-08-14T18:25:16.503776Z","iopub.status.idle":"2024-08-14T18:25:16.511446Z","shell.execute_reply.started":"2024-08-14T18:25:16.503741Z","shell.execute_reply":"2024-08-14T18:25:16.510603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Avaliar o modelo no conjunto de teste\nall_preds, all_labels = test_model(modelo, teste_loader)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T18:25:16.512686Z","iopub.execute_input":"2024-08-14T18:25:16.513006Z","iopub.status.idle":"2024-08-14T18:25:23.38265Z","shell.execute_reply.started":"2024-08-14T18:25:16.512977Z","shell.execute_reply":"2024-08-14T18:25:23.381593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ajustar escala dos gráficos\ndef ajustar_escala(hist):\n    hist['train_acc'] = [acc * 100 for acc in hist['train_acc']]\n    hist['val_acc'] = [acc * 100 for acc in hist['val_acc']]\n    return hist\n\n# Função para plotar as curvas de aprendizado\ndef plot_learning_curves(train_acc, val_acc, train_loss, val_loss):\n    fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n    ax = ax.flatten()\n\n    # Curva de Acurácia\n    ax[0].plot(train_acc, label='Treino', color='blue')\n    ax[0].plot(val_acc, label='Validação', color='orange')\n    ax[0].set_title('Acurácia do Modelo')\n    ax[0].set_xlabel('Épocas')\n    ax[0].set_ylabel('Acurácia (%)')\n    ax[0].legend()\n\n    # Curva de Perda\n    ax[1].plot(train_loss, label='Treino', color='blue')\n    ax[1].plot(val_loss, label='Validação', color='orange')\n    ax[1].set_title('Erro do Modelo')\n    ax[1].set_xlabel('Épocas')\n    ax[1].set_ylabel('Erro')\n    ax[1].legend()\n\n    plt.tight_layout()\n    plt.show()\n\n# Plotar as curvas de aprendizado\nplot_learning_curves(train_accuracy_history, val_accuracy_history, train_loss_history, val_loss_history)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T18:25:23.383707Z","iopub.execute_input":"2024-08-14T18:25:23.383955Z","iopub.status.idle":"2024-08-14T18:25:24.266648Z","shell.execute_reply.started":"2024-08-14T18:25:23.383932Z","shell.execute_reply":"2024-08-14T18:25:24.265739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\ndef test_model(model, test_loader):\n    model.eval()  # Colocar o modelo em modo de avaliação\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)  # Obtém o índice da classe com maior pontuação\n\n            all_preds.extend(preds.cpu().numpy())  # Adicionar as previsões à lista\n            all_labels.extend(labels.cpu().numpy())  # Adicionar os rótulos verdadeiros à lista\n\n    return all_preds, all_labels\n\n# Avaliar o modelo no conjunto de teste\nall_preds, all_labels = test_model(modelo, teste_loader)\n\n# Certifique-se de que all_preds e all_labels são listas ou arrays\nall_labels = np.array(all_labels)\nall_preds = np.array(all_preds)\n\nprint(\"Tipo de all_labels:\", type(all_labels))\nprint(\"Tipo de all_preds:\", type(all_preds))\nprint(\"Comprimento de all_labels:\", len(all_labels))\nprint(\"Comprimento de all_preds:\", len(all_preds))\n\n# Verifique target_names\nprint(\"Classes no conjunto de teste:\", teste_dataset.classes)\n\n# Relatório de Classificação\nprint(\"Relatório de Classificação:\")\nprint(classification_report(all_labels, all_preds, target_names=teste_dataset.classes))\n\n# Matriz de Confusão\nprint(\"Matriz de Confusão:\")\nprint(confusion_matrix(all_labels, all_preds))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T18:25:24.267855Z","iopub.execute_input":"2024-08-14T18:25:24.268139Z","iopub.status.idle":"2024-08-14T18:25:30.771919Z","shell.execute_reply.started":"2024-08-14T18:25:24.268114Z","shell.execute_reply":"2024-08-14T18:25:30.770947Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
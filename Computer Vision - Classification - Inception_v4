{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importação de dados","metadata":{}},{"cell_type":"code","source":"import os\nimport zipfile\n\n# Criar o diretório para a configuração do Kaggle\nos.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n\n# Copiar o arquivo kaggle.json para o diretório de configuração\n# Certifique-se de que você adicionou o arquivo kaggle.json nos dados do notebook\n!cp /kaggle/input/kaggle-json/kaggle.json ~/.kaggle/\n\n# Ajustar as permissões do arquivo kaggle.json\n!chmod 600 ~/.kaggle/kaggle.json\n\n# Baixar o conjunto de dados do Kaggle\n!kaggle datasets download -d maeloisamignoni/soybeanleafdataset\n\n# Descompactar o arquivo baixado\nwith zipfile.ZipFile('soybeanleafdataset.zip', 'r') as zip_ref:\n    zip_ref.extractall('soybeanleafdataset')","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:38:24.532822Z","iopub.execute_input":"2024-06-28T03:38:24.533170Z","iopub.status.idle":"2024-06-28T03:38:36.557994Z","shell.execute_reply.started":"2024-06-28T03:38:24.533140Z","shell.execute_reply":"2024-06-28T03:38:36.556809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#diretório de base e classes\nbase_dir = '/kaggle/working/soybeanleafdataset/soybean.leaf.dataset'\nclasses = ['Caterpillar', 'Diabrotica speciosa', 'Healthy']","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:38:36.560116Z","iopub.execute_input":"2024-06-28T03:38:36.560430Z","iopub.status.idle":"2024-06-28T03:38:36.565172Z","shell.execute_reply.started":"2024-06-28T03:38:36.560401Z","shell.execute_reply":"2024-06-28T03:38:36.564299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install -q split-folders\n#!pip install -q timm","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:38:36.566371Z","iopub.execute_input":"2024-06-28T03:38:36.566687Z","iopub.status.idle":"2024-06-28T03:38:36.579784Z","shell.execute_reply.started":"2024-06-28T03:38:36.566662Z","shell.execute_reply":"2024-06-28T03:38:36.578908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install split-folders","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:38:36.580949Z","iopub.execute_input":"2024-06-28T03:38:36.581287Z","iopub.status.idle":"2024-06-28T03:38:51.255066Z","shell.execute_reply.started":"2024-06-28T03:38:36.581254Z","shell.execute_reply":"2024-06-28T03:38:51.254001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q torch torchvision timm tensorflow split-folders seaborn","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:38:51.257871Z","iopub.execute_input":"2024-06-28T03:38:51.258195Z","iopub.status.idle":"2024-06-28T03:39:06.827480Z","shell.execute_reply.started":"2024-06-28T03:38:51.258167Z","shell.execute_reply":"2024-06-28T03:39:06.826281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importação de bibliotecas","metadata":{}},{"cell_type":"code","source":"# Importar bibliotecas necessárias\n\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch\nimport tensorflow as tf\nimport splitfolders\nimport shutil\nimport seaborn as sns\nimport random\nimport pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision.models import vgg19\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, load_img, img_to_array\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport timm\nimport timm\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\nfrom timm.data.mixup import Mixup\nfrom timm.data.random_erasing import RandomErasing\n\n# Configurar alguns parâmetros de visualização\nsns.set(style=\"whitegrid\")\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['image.cmap'] = 'viridis'","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:39:06.828949Z","iopub.execute_input":"2024-06-28T03:39:06.829261Z","iopub.status.idle":"2024-06-28T03:39:25.130622Z","shell.execute_reply.started":"2024-06-28T03:39:06.829232Z","shell.execute_reply":"2024-06-28T03:39:25.129864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Função para plotar imagens de cada classe\ndef plot_images(class_name, n_images=5):\n    class_dir = os.path.join(base_dir, class_name)\n    if os.path.exists(class_dir):\n        images = os.listdir(class_dir)[:n_images]\n\n        plt.figure(figsize=(15, 5))\n        for i, img_name in enumerate(images):\n            img_path = os.path.join(class_dir, img_name)\n            img = load_img(img_path, target_size=(150, 150))\n            plt.subplot(1, n_images, i+1)\n            plt.imshow(img)\n            plt.title(class_name)\n            plt.axis('off')\n        plt.show()\n    else:\n        print(f'Diretório {class_dir} não encontrado.')\n\n# Visualizar algumas imagens de cada classe\nfor cls in classes:\n    plot_images(cls)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:39:25.131709Z","iopub.execute_input":"2024-06-28T03:39:25.131987Z","iopub.status.idle":"2024-06-28T03:39:27.854078Z","shell.execute_reply.started":"2024-06-28T03:39:25.131964Z","shell.execute_reply":"2024-06-28T03:39:27.853146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verificar a estrutura das pastas e contar o número de imagens em cada classe\nfor cls in classes:\n    class_dir = os.path.join(base_dir, cls)\n    if os.path.exists(class_dir):\n        num_images = len(os.listdir(class_dir))\n        print(f'Classe {cls} contém {num_images} imagens.')\n    else:\n        print(f'Diretório {class_dir} não encontrado.')","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:39:27.855209Z","iopub.execute_input":"2024-06-28T03:39:27.855493Z","iopub.status.idle":"2024-06-28T03:39:27.865470Z","shell.execute_reply.started":"2024-06-28T03:39:27.855468Z","shell.execute_reply":"2024-06-28T03:39:27.864561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configurar data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:39:27.866950Z","iopub.execute_input":"2024-06-28T03:39:27.867290Z","iopub.status.idle":"2024-06-28T03:39:27.872548Z","shell.execute_reply.started":"2024-06-28T03:39:27.867267Z","shell.execute_reply":"2024-06-28T03:39:27.871395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport matplotlib.pyplot as plt\n\n# Inicializar o gerador de dados com aumento\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Função para aumentar imagens\ndef augment_images(class_name, target_count):\n    class_dir = os.path.join(base_dir, class_name)\n    images = os.listdir(class_dir)\n    current_count = len(images)\n\n    # Loop até atingir o número desejado de imagens\n    while current_count < target_count:\n        img_name = random.choice(images)\n        img_path = os.path.join(class_dir, img_name)\n        img = load_img(img_path)\n        x = img_to_array(img)  # Converte a imagem em array\n        x = x.reshape((1,) + x.shape)  # Redimensiona para (1, largura, altura, 3)\n\n        # Gerar imagens aumentadas\n        i = 0\n        for batch in datagen.flow(x, batch_size=1, save_to_dir=class_dir, save_prefix='aug', save_format='jpeg'):\n            i += 1\n            if i >= 1:  # Gerar uma imagem aumentada por iteração\n                break\n\n        current_count += 1\n        if current_count % 100 == 0:\n            print(f'{current_count} imagens geradas para a classe {class_name}')\n\n# Número alvo de imagens para cada classe\ntarget_count = 3309\n\n# Aplicar data augmentation nas classes menos representadas\naugment_images('Diabrotica speciosa', target_count)\naugment_images('Healthy', target_count)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:39:27.873903Z","iopub.execute_input":"2024-06-28T03:39:27.874252Z","iopub.status.idle":"2024-06-28T03:43:12.822637Z","shell.execute_reply.started":"2024-06-28T03:39:27.874222Z","shell.execute_reply":"2024-06-28T03:43:12.821638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verificar a estrutura das pastas e contar o número de imagens em cada classe\nfor cls in classes:\n    class_dir = os.path.join(base_dir, cls)\n    if os.path.exists(class_dir):\n        num_images = len(os.listdir(class_dir))\n        print(f'Classe {cls} contém {num_images} imagens.')\n    else:\n        print(f'Diretório {class_dir} não encontrado.')","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:43:12.824013Z","iopub.execute_input":"2024-06-28T03:43:12.824380Z","iopub.status.idle":"2024-06-28T03:43:12.837400Z","shell.execute_reply.started":"2024-06-28T03:43:12.824348Z","shell.execute_reply":"2024-06-28T03:43:12.836388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dividir os dados em treino, validação e teste\nsplitfolders.ratio(base_dir,\n                   output=\"dataset\",\n                   seed=100,\n                   ratio=(.7, .2, .1),\n                   group_prefix=None,\n                   move=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:43:12.838491Z","iopub.execute_input":"2024-06-28T03:43:12.838782Z","iopub.status.idle":"2024-06-28T03:43:14.950312Z","shell.execute_reply.started":"2024-06-28T03:43:12.838758Z","shell.execute_reply":"2024-06-28T03:43:14.949444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelo teste AdamW","metadata":{}},{"cell_type":"code","source":"# Definir diretórios base\ntrain_dir = '/kaggle/working/dataset/train'\nval_dir = '/kaggle/working/dataset/val'\ntest_dir = '//kaggle/working/dataset/test'\n\n# Transformações de dados\ntransformacoes_treino = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntransformacoes_valid = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntransformacoes_teste = transformacoes_valid\n\n# Carregar dados\ntreino_dataset = datasets.ImageFolder(root=train_dir, transform=transformacoes_treino)\nvalid_dataset = datasets.ImageFolder(root=val_dir, transform=transformacoes_valid)\nteste_dataset = datasets.ImageFolder(root=test_dir, transform=transformacoes_teste)\n\n# Criar DataLoaders\nbatch_size = 32\ntreino_loader = DataLoader(treino_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\nteste_loader = DataLoader(teste_dataset, batch_size=batch_size, shuffle=False)\n\n# Verificar se os dados foram carregados corretamente\nfor images, labels in treino_loader:\n    print(f\"Lote de treino - Imagens: {images.size()}, Labels: {labels.size()}\")\n    break\n\n# Dispositivo de treinamento (GPU se disponível)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:43:14.951496Z","iopub.execute_input":"2024-06-28T03:43:14.951799Z","iopub.status.idle":"2024-06-28T03:43:15.468849Z","shell.execute_reply.started":"2024-06-28T03:43:14.951774Z","shell.execute_reply":"2024-06-28T03:43:15.467911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Carregar o modelo Inception v4 pré-treinado no ImageNet\nmodelo = timm.create_model('inception_v4', pretrained=True)\nnum_ftrs = modelo.get_classifier().in_features\nmodelo.classifier = nn.Sequential(\n    nn.Dropout(0.5),\n    nn.Linear(num_ftrs, 1000),\n)\nmodelo = modelo.to(device)\n\n# Definir o otimizador e a função de perda\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(modelo.parameters(), lr=0.001, momentum=0.9)\n\n# Função para treinar o modelo\ndef train_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=50):\n    train_loss_history = []\n    val_loss_history = []\n    train_accuracy_history = []\n    val_accuracy_history = []\n\n    print(\"\\nTreinamento Iniciado!\\n\")\n\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset) * 100\n\n        train_loss_history.append(epoch_loss)\n        train_accuracy_history.append(epoch_acc.item())\n\n        model.eval()\n        val_running_loss = 0.0\n        val_running_corrects = 0\n\n        with torch.no_grad():\n            for inputs, labels in valid_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                _, preds = torch.max(outputs, 1)\n                val_running_loss += loss.item() * inputs.size(0)\n                val_running_corrects += torch.sum(preds == labels.data)\n\n        val_loss = val_running_loss / len(valid_loader.dataset)\n        val_acc = val_running_corrects.double() / len(valid_loader.dataset) * 100\n\n        val_loss_history.append(val_loss)\n        val_accuracy_history.append(val_acc.item())\n\n        print(f'Epoch: {epoch} - Acurácia em Treino: {epoch_acc:.2f} - Acurácia em Validação: {val_acc:.2f} - Erro em Treino: {epoch_loss:.4f} - Erro em Validação: {val_loss:.4f}')\n\n    print(\"\\nTreinamento Concluído!\\n\")\n    return train_accuracy_history, val_accuracy_history, train_loss_history, val_loss_history\n\n# Treinar o modelo\ntrain_accuracy_history, val_accuracy_history, train_loss_history, val_loss_history = train_model(modelo, criterion, optimizer, treino_loader, valid_loader, num_epochs=50)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:44:37.249460Z","iopub.execute_input":"2024-06-28T03:44:37.249876Z","iopub.status.idle":"2024-06-28T06:25:01.372382Z","shell.execute_reply.started":"2024-06-28T03:44:37.249846Z","shell.execute_reply":"2024-06-28T06:25:01.371396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_model(model, test_loader):\n    model.eval()\n    test_running_loss = 0.0\n    test_running_corrects = 0\n\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            _, preds = torch.max(outputs, 1)\n            test_running_loss += loss.item() * inputs.size(0)\n            test_running_corrects += torch.sum(preds == labels.data)\n\n    test_loss = test_running_loss / len(test_loader.dataset)\n    test_acc = test_running_corrects.double() / len(test_loader.dataset) * 100\n\n    print(f'Acurácia em Teste: {test_acc:.2f} - Erro em Teste: {test_loss:.4f}')\n    return test_acc.item(), test_loss","metadata":{"execution":{"iopub.status.busy":"2024-06-28T06:25:01.374071Z","iopub.execute_input":"2024-06-28T06:25:01.374368Z","iopub.status.idle":"2024-06-28T06:25:01.381316Z","shell.execute_reply.started":"2024-06-28T06:25:01.374342Z","shell.execute_reply":"2024-06-28T06:25:01.380575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Avaliar o modelo no conjunto de teste\nall_preds, all_labels = test_model(modelo, teste_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T06:25:01.382426Z","iopub.execute_input":"2024-06-28T06:25:01.382706Z","iopub.status.idle":"2024-06-28T06:25:10.489418Z","shell.execute_reply.started":"2024-06-28T06:25:01.382683Z","shell.execute_reply":"2024-06-28T06:25:10.488582Z"},"trusted":true},"execution_count":null,"outputs":[]}]}